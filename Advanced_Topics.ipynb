{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qndnYAQpL6I8"
   },
   "source": [
    "In this notebok we have developed a system to detect irony in text. We will use the data from the SemEval-2018 task on irony detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEvckziyL6I9"
   },
   "source": [
    "```csv\n",
    "Tweet index     Label   Tweet text\n",
    "1       1       Sweet United Nations video. Just in time for Christmas. #imagine #NoReligion  http://t.co/fej2v3OUBR\n",
    "2       1       @mrdahl87 We are rumored to have talked to Erv's agent... and the Angels asked about Ed Escobar... that's hardly nothing    ;)\n",
    "3       1       Hey there! Nice to see you Minnesota/ND Winter Weather \n",
    "4       0       3 episodes left I'm dying over here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oc7hUIIjL6I9"
   },
   "source": [
    "\n",
    "Read all the data and find the size of vocabulary of the dataset (ignoring case) and the number of positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 59,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "8oBIlNurcYGE",
    "outputId": "641d823d-8171-4b3e-e851-896ead97525d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3c7eaa63-9ec1-433f-8113-d45ac0c8ec66\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-3c7eaa63-9ec1-433f-8113-d45ac0c8ec66\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C9D365yTcxUS",
    "outputId": "5815aa08-dc03-466a-fa51-19badb862ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8EovBBVlNmx"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('1600599.txt', sep=\"\\t\")\n",
    "\n",
    "#Preprocessing\n",
    "stop = stopwords.words('english')\n",
    "stem = PorterStemmer()\n",
    "del df['Tweet index']\n",
    "df['Tweet text'] = df['Tweet text'].apply(lambda x: \" \".join(stem.stem(item.lower()) for item in x.split() if item not in stop))\n",
    "df['Tweet text'] = df['Tweet text'].apply(lambda x: \" \".join(item for item in x.split() if item not in stop))\n",
    "df['Tweet text'] = df['Tweet text'].replace(to_replace=r'^https?:\\/\\/.*[\\r\\n]*',value='',regex=True)\n",
    "df['Tweet text'] = df['Tweet text'].replace(to_replace=r'@[^\\s]+',value='',regex=True)\n",
    "\n",
    "pos_neg = df.groupby(['Label']).size().tolist()\n",
    "\n",
    "count = []\n",
    "for i in df['Tweet text']:\n",
    "  w = i.split()\n",
    "  count.extend(w)\n",
    "vocab_size = len(set((count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "bXbePxclWLvo",
    "outputId": "e7c44ce6-407b-4501-98c5-7c40eced6dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    sweet unit nation video. time christmas. #imag...\n",
       "1    rumor talk erv' agent... angel ask ed escobar....\n",
       "2      hey there! nice see minnesota/nd winter weather\n",
       "3                                3 episod left i'm die\n",
       "4    can't breathe! chosen notabl quot year annual ...\n",
       "Name: Tweet text, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "# def clean(data):\n",
    "  \n",
    "df['Tweet text'] = df['Tweet text'].apply(lambda x: \" \".join(item.lower() for item in x.split() if item not in stop))\n",
    "df['Tweet text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5LivWxOL6JA"
   },
   "source": [
    "Divide the data into a training and test set and justify your split.\n",
    "\n",
    "Implement a function that calculates the precision, recall and F-Measure for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "R8odhXV4mJoA",
    "outputId": "d91156b7-095a-4d45-8602-cfe752a3b687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3053,), (3053,))"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_cutoff = int(.80 * len(df)) \n",
    "training_sentences = df[:train_test_cutoff]\n",
    "testing_sentences = df[train_test_cutoff:]\n",
    "X_train = training_sentences['Tweet text']\n",
    "X_test = testing_sentences['Tweet text']\n",
    "y_train = training_sentences['Label']\n",
    "y_test = testing_sentences['Label']\n",
    "y_test_org = y_test\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def evaluation(y_pred, y_true):\n",
    "  precision, recall, fscore, support = precision_recall_fscore_support(np.array(y_true),np.array(y_pred), average='macro')\n",
    "  return precision, recall, fscore\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sUTG6yuikS2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nU9HGp4eo_0C"
   },
   "source": [
    "Suggesting some features to extract from each sentence. Implementing a simple log-linear model to classify tweets as ironic or not ironic.\n",
    "Train this method and evaluate the results using precision, recall and F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3qFAD5ND9RMW",
    "outputId": "7aff5622-114f-49cb-9c77-a8218083f5d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3053, 8487), (3053,))"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer().fit(X_train,X_test)\n",
    "X_train = cvec.transform(X_train).toarray()\n",
    "X_test = cvec.transform(X_test).toarray()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vq5kxnBnTtA0",
    "outputId": "18074a1b-e9cd-41b8-fd24-02f6eec2f11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6131443920245188 0.6127305665349143 0.6127591213284881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "precision,recall,fscore = evaluation(y_pred,y_test)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82JnhmgBL6JA"
   },
   "source": [
    "Developed an acceptor or a transducer recurrent neural network that classifiers the sentence as ironic or not ironic.\n",
    "\n",
    "Evaluate this according to precision, recall or F-Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y9EcadIv8Zav",
    "outputId": "6e781197-9f0f-4da0-a145-e7461159262f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3053, 64), (764, 64), (3053, 2), (764, 2))"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "out_dim,max_len = 64,64\n",
    "X_train = training_sentences['Tweet text'].tolist()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=max_len)\n",
    "\n",
    "X_test = testing_sentences['Tweet text'].tolist()\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=max_len)\n",
    "y_train= to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "pwVoTmdMQczt",
    "outputId": "01df57e8-0a63-4d73-dc4a-7002dd7c58f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3053 samples, validate on 764 samples\n",
      "Epoch 1/5\n",
      "3053/3053 [==============================] - 25s 8ms/sample - loss: 0.7388 - accuracy: 0.5524 - val_loss: 0.6630 - val_accuracy: 0.5877\n",
      "Epoch 2/5\n",
      "3053/3053 [==============================] - 22s 7ms/sample - loss: 0.5663 - accuracy: 0.7588 - val_loss: 0.7955 - val_accuracy: 0.5955\n",
      "Epoch 3/5\n",
      "3053/3053 [==============================] - 22s 7ms/sample - loss: 0.2930 - accuracy: 0.9086 - val_loss: 2.0814 - val_accuracy: 0.5792\n",
      "Epoch 4/5\n",
      "3053/3053 [==============================] - 22s 7ms/sample - loss: 4.7311 - accuracy: 0.6811 - val_loss: 7.3875 - val_accuracy: 0.5183\n",
      "Epoch 5/5\n",
      "3053/3053 [==============================] - 22s 7ms/sample - loss: 7.7012 - accuracy: 0.4979 - val_loss: 7.3875 - val_accuracy: 0.5183\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, out_dim))\n",
    "model.add(tf.keras.layers.LSTM(out_dim, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(out_dim, return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x = X_train,y= y_train ,epochs=5,batch_size = 10,\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjGvGEhWv7EJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "0LzJb-rebUaF",
    "outputId": "5b81efdc-024d-4e93-b988-9bd3bdd04903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764/764 [==============================] - 1s 746us/sample - loss: 7.3875 - accuracy: 0.5183\n",
      "0.2591623036649215 0.5 0.3413793103448276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x= X_test , y = y_test )\n",
    "y_pred = model.predict_classes(X_test)\n",
    "precision,recall,fscore = evaluation(y_pred,y_test_org)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yZucGZmL6JM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "qP6S0Dj2q7Va",
    "outputId": "7ff604b3-d5ba-4889-a523-c39d33d44a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3053 samples, validate on 764 samples\n",
      "Epoch 1/5\n",
      "3053/3053 [==============================] - 72s 23ms/sample - loss: 0.7250 - accuracy: 0.4998 - val_loss: 0.6913 - val_accuracy: 0.5366\n",
      "Epoch 2/5\n",
      "3053/3053 [==============================] - 60s 20ms/sample - loss: 0.6504 - accuracy: 0.6289 - val_loss: 0.6669 - val_accuracy: 0.5890\n",
      "Epoch 3/5\n",
      "3053/3053 [==============================] - 59s 19ms/sample - loss: 0.4397 - accuracy: 0.8354 - val_loss: 1.1138 - val_accuracy: 0.6041\n",
      "Epoch 4/5\n",
      "3053/3053 [==============================] - 58s 19ms/sample - loss: 0.2375 - accuracy: 0.9245 - val_loss: 1.3699 - val_accuracy: 0.5870\n",
      "Epoch 5/5\n",
      "3053/3053 [==============================] - 57s 19ms/sample - loss: 0.1953 - accuracy: 0.9455 - val_loss: 1.9618 - val_accuracy: 0.5609\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim = out_dim))\n",
    "model.add(tf.keras.layers.LSTM(64,dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(32,dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(8,dropout=0.2, recurrent_dropout=0.2,return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x = X_train,y= y_train ,epochs=5,batch_size = 10,\n",
    "                    validation_data=(X_test, y_test)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "V1LVa_fSvcbT",
    "outputId": "81316ab6-8399-450c-80bd-d28d03d5e610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764/764 [==============================] - 1s 929us/sample - loss: 1.9618 - accuracy: 0.5609\n",
      "0.5880041011619959 0.5848155467720686 0.5785525154457194\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x= X_test , y = y_test )\n",
    "y_pred = model.predict_classes(X_test)\n",
    "precision,recall,fscore = evaluation(y_pred,y_test_org)\n",
    "print(precision, recall, fscore)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Advanced_Topics_in_Natural_Language_Processing_Assignment_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
